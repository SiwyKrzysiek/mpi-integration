# CaÅ‚kowanie z zastosowaniem standardu MPI

RÃ³wnolegÅ‚e obliczanie caÅ‚ki oznaczonej z zastosowaniem metod numerycznych.

<!-- Link do repozytorium: https://github.com/SiwyKrzysiek/mpi-integration -->

## Spis treÅ›ci

- [CaÅ‚kowanie z zastosowaniem standardu MPI](#caÅ‚kowanie-z-zastosowaniem-standardu-mpi)
  - [Spis treÅ›ci](#spis-treÅ›ci)
  - [TreÅ›Ä‡ zadania](#treÅ›Ä‡-zadania)
    - [Zadania do wykonania w ramach Ä‡wiczenia](#zadania-do-wykonania-w-ramach-Ä‡wiczenia)
  - [Realizacja zadania](#realizacja-zadania)
    - [Uruchomienie programu](#uruchomienie-programu)
  - [Zadania dodatkowe](#zadania-dodatkowe)
    - [Napisanie programu z wykorzystaniem komunikacji grupowej](#napisanie-programu-z-wykorzystaniem-komunikacji-grupowej)
    - [Napisanie programu z wykorzystaniem komunikacji nieblokujÄ…cej](#napisanie-programu-z-wykorzystaniem-komunikacji-nieblokujÄ…cej)
    - [Uruchomienie programu na kilku maszynach](#uruchomienie-programu-na-kilku-maszynach)
  - [Nowe zadania](#nowe-zadania)
    - [CaÅ‚kowanie z wykorzystaniem komunikacji grupowej](#caÅ‚kowanie-z-wykorzystaniem-komunikacji-grupowej)
    - [CaÅ‚kowanie z wykorzystaniem komunikacji nieblokujÄ…cej](#caÅ‚kowanie-z-wykorzystaniem-komunikacji-nieblokujÄ…cej)

## TreÅ›Ä‡ zadania

ProszÄ™ policzyÄ‡ przy pomocy metody prostokÄ…tÃ³w/trapezÃ³w/Simpsona (moÅ¼ecie PaÅ„stwo wybraÄ‡ metodÄ™) caÅ‚kÄ™ oznaczonÄ… funkcji jednej zmiennej. Procedura caÅ‚kowania powinna przyjmowaÄ‡: wskaÅºnik na caÅ‚kowanÄ… funkcjÄ™, poczÄ…tek i koniec przedziaÅ‚u caÅ‚kowania oraz liczbÄ™ punktÃ³w dla ktÃ³rych obliczana jest wartoÅ›Ä‡ funkcji. Oto jej nagÅ‚Ã³wek:

```c
double integrate(double (*func)(double), double begin, double end, int num_points);
```

CaÅ‚kowanie powinno byÄ‡ wykonane rÃ³wnolegle przy uÅ¼yciu standardu MPI. Wybrany proces gÅ‚Ã³wny rozdziela przedziaÅ‚ caÅ‚kowania oraz liczbÄ™ punktÃ³w, w ktÃ³rych bÄ™dÄ… wykonywane obliczenia pomiÄ™dzy siebie i pozostaÅ‚e procesy. RozsyÅ‚a potrzebne informacje do pozostaÅ‚ych procesÃ³w oraz wykonuje swojÄ… czÄ™Å›Ä‡ obliczeÅ„. NastÄ™pnie zbiera wyniki od pozostaÅ‚ych procesÃ³w i sumuje je ze swoim wynikiem czÄ…stkowym. Ostatecznie wypisuje wynik caÅ‚kowity na standardowe wyjÅ›cie. ProszÄ™ zwrÃ³ciÄ‡ uwagÄ™ na to, Å¼e kaÅ¼dy z procesÃ³w powinien liczyÄ‡ caÅ‚kÄ™ dla pewnej liczby punktÃ³w, ktÃ³ra zostaÅ‚a mu przydzielona przez proces gÅ‚Ã³wny (suma punktÃ³w z wszystkich procesÃ³w powinna byÄ‡ rÃ³wna liczbie podanej jako argument wejÅ›ciowy) â€“ zatem proces gÅ‚Ã³wny powinien dokonaÄ‡ rozsÄ…dnego podziaÅ‚u danych wejÅ›ciowych pomiÄ™dzy procesy.

Program powinien pozwalaÄ‡ na ustawienie poczÄ…tku i koÅ„ca przedziaÅ‚u caÅ‚kowania oraz caÅ‚kowitej liczby punktÃ³w. Program powinien dziaÅ‚aÄ‡ poprawnie dla dowolnej, zadanej przez prowadzÄ…cego, liczby procesÃ³w oraz liczby punktÃ³w. Komunikacja pomiÄ™dzy procesami powinna zostaÄ‡ zrealizowana jedynie przy uÅ¼yciu funkcji (`MPI_Send`, `MPI_Recv`).

Interfejs programu powinien wyglÄ…daÄ‡ nastÄ™pujÄ…co:

`./integrate begin end num_points`

### Zadania do wykonania w ramach Ä‡wiczenia

1. Napisanie procedury caÅ‚kowania
2. PodziaÅ‚ liczby punktÃ³w na poszczegÃ³lne procesy (moÅ¼liwie rÃ³wny!)
3. PodziaÅ‚ przedziaÅ‚Ã³w caÅ‚kowania dla poszczegÃ³lnych procesÃ³w
4. RozesÅ‚anie do procesÃ³w â€robotnikÃ³wâ€ danych umoÅ¼liwiajÄ…cych obliczenia czÄ…stkowe.
5. OdbiÃ³r danych przez procesy.
6. Wykonanie obliczeÅ„ w procesie gÅ‚Ã³wnym.
7. Wykonanie obliczeÅ„ w procesach â€robotnikachâ€
8. PrzesÅ‚anie obliczeÅ„ czÄ…stkowych do procesu gÅ‚Ã³wnego.
9. Zsumowanie wszystkich wynikÃ³w i wyÅ›wietlenie wyniku koÅ„cowego.

## Realizacja zadania

> Podczas pracy z _Open MPI_ zainstalowanym przy pomocy brew po zakoÅ„czeniu programu pojawiaÅ‚ siÄ™Â bÅ‚Ä…d. PomogÅ‚o ustawienie zmiennej Å›rodowiskowej `PMIX_MCA_gds=hash`

GÅ‚owna czeÅ›Ä‡ zadania jest realizowane przez funkcjÄ™Â `double integrate(double (*func)(double), double begin, double end, int num_points)`.

Jej wykonanie przebiega rÃ³Å¼nie w zaleÅ¼noÅ›ci od tego czy aktualny proces jest procesem gÅ‚Ã³wnym.
Proces gÅ‚Ã³wny przygotowuje punkty, w ktÃ³rych bÄ™dzie liczona wartoÅ›Ä‡ funkcji oraz moÅ¼liwie rÃ³wny podziaÅ‚ wygenerowanych punktÃ³w miÄ™dzy siebie i pozostaÅ‚e procesy.
Do podziaÅ‚u zostaÅ‚ wykorzystany algorytm, ktÃ³ry napisaÅ‚em na potrzeby wczeÅ›niejszych zadaÅ„.  
Po przygotowaniu podziaÅ‚u proces gÅ‚Ã³wny przesyÅ‚a do wszystkich pozostaÅ‚ych punkty, na ktÃ³rych majÄ… one dokonaÄ‡ obliczeÅ„. Jest to wykonane za pomocÄ…Â 2 instrukcji `MPI_Send()`, gdzie pierwsza przesyÅ‚a iloÅ›Ä‡Â danych a druga dane.

W miÄ™dzy czasie procesy nie bÄ™dÄ…ce procesem gÅ‚Ã³wnym oczekujÄ… na dane przy pomocy funkcji `MPI_Recv()`.

Po otrzymaniu danych, kaÅ¼dy proces wykonuje na nich funkcjÄ™ `integrateRange()`, ktÃ³ra liczy wartoÅ›Ä‡ caÅ‚ki korzystajÄ…c z podanych punktÃ³w jako wÄ™zÅ‚Ã³w. Po zakoÅ„czeniu obliczeÅ„ procesy przesyÅ‚ajÄ… swoje wyniki do procesu gÅ‚Ã³wnego, gdzie sÄ… one sumowane do wartoÅ›ci caÅ‚kowitej.

### Uruchomienie programu

PoniewaÅ¼ program korzysta ze standardu _MPI_ wymaga odpowiedniego kompilatora oraz programu uruchamiajÄ…cego. Pozwala to na Å‚atwe utworzenie i zarzÄ…dzanie pulÄ… procesÃ³w.

Przed uruchomieniem programu trzeba zainstalowaÄ‡ `mpicc` oraz `mpirun`. W przypadku sytemu OS X moÅ¼na to zrobiÄ‡ poleceniem `brew install open-mpi`.

BÄ™dÄ…c **w katalogu ./integrate** program moÅ¼na Å‚atwo zbudowaÄ‡ przy pomocy narzÄ™dzia _make_.

```bash
make
```

W celu dodanie wyÅ›wietlenia szczegÃ³Å‚owych informacji o dziaÅ‚aniu programu moÅ¼na skorzystaÄ‡ z celu `make debug`.

Uruchomienie programu do uruchomienia programu trzeba wykorzystaÄ‡ `mpiexec`.

PrzykÅ‚adowe uruchomienie:

```txt
âœ mpiexec -n 4 ./integrate 0 2 10000
Program will integrate function y = x^2
Result: 2.665967
```

Program jest uruchomiony z 4 procesami, liczy caÅ‚kÄ™ dla przedziaÅ‚u od 0 do 2 z wykorzystaniem 10000 wÄ™zÅ‚Ã³w.

## Zadania dodatkowe

Realizacja dodatkowych zadaÅ„ z iSoda.
Przy pierwszym podejÅ›ciu do tego zadania zrozumiaÅ‚em, Å¼e naleÅ¼y napisaÄ‡ dowolne programy dobrze obrazujÄ…ce wykorzystanie podanych rodzajÃ³w komunikacji.
Wersje programu caÅ‚kujÄ…cego z wykorzystaniem rÃ³Å¼nych metod komunikacji znajdujÄ…Â siÄ™ w sekcji [Nowe zadania](#Nowe-zadania).

### Napisanie programu z wykorzystaniem komunikacji grupowej

W celu przetestowania komunikacji grupowej napisany zostaÅ‚ program obliczajÄ…cy Å›redniÄ… wartoÅ› liczby zwracanej przez generator pseudolosowy.

Kod programu znajduje siÄ™ w katalogu [additional_tasks/group_communication](./additional_tasks/group_communication).

Program wykorzystuje funkcjÄ™ `MPI_Scatter()` do rozesÅ‚ania czÄ™Å›ci tablicy miÄ™dzy podppoorgramy.
NastÄ™pnie kaÅ¼dy podprogram, razem z gÅ‚Ã³wnym, obliczajÄ… Å›redniÄ…Â czÄ…stkowÄ… swojej czÄ™Å›ci danych.

Wyniki czÄ…stkowe sÄ…Â sumowane i zwracane do procesu gÅ‚Ã³wnego przy pomocy funkcji `MPI_Reduce()`.

Program kompiluje siÄ™ i uruchamia analogicznie jak program gÅ‚Ã³wny, ale nie przyjmuje on argumentÃ³w.

### Napisanie programu z wykorzystaniem komunikacji nieblokujÄ…cej

W celu poznania komunikacji nieblokujÄ…cej napisany zostaÅ‚ prosty program symulujÄ…cy restauracjÄ™ dostarczajÄ…cÄ… pizze.
Program znajduje siÄ™ w katalogu [additional_tasks/non_blocking_communication](./additional_tasks/non_blocking_communication).

Za rÃ³wno klient jak i pizzeria majÄ…Â swoje zajÄ™cia, ktÃ³re realizujÄ™Â w oczekiwaniu na komunikacjÄ™.
Pizzeria jeÅ›li nie ma zamÃ³wienia do realizacji zajmuje siÄ™ klientami w lokali i tylko okresowo sprawdza czy sÄ…Â jakieÅ› zamÃ³wienia.  
Klient w oczekiwaniu na zamÃ³wienie oddaje siÄ™ pracy. Tylko raz na jakiÅ› czas wychodzi na ganek swojego domu i sprawdza czy nie pojawiÅ‚a siÄ™ tam pizza ğŸ•.

Program kompiluje siÄ™ i uruchamia analogicznie jak program gÅ‚Ã³wny, ale nie przyjmuje on argumentÃ³w.

### Uruchomienie programu na kilku maszynach

Przy prÃ³bie realizacji zadania wzorowaÅ‚em siÄ™Â artykuÅ‚em [Running an MPI Cluster within a LAN](https://mpitutorial.com/tutorials/running-an-mpi-cluster-within-a-lan/).

Do uruchomienia programu mpi na kilku maszynach ciaÅ‚em wykorzystaÄ‡ dwie maszyny wirtualne Ubuntu.

Na poczÄ…tek zadbaÅ‚em o komunikacjÄ™ miÄ™dzy maszynami. W tym celu podÅ‚Ä…czyÅ‚em je interfejsem mostkowym do sieci gospodarza.
UmoÅ¼liwiÅ‚em rÃ³wnieÅ¼ komunikacjÄ™ shh bez podawania hasÅ‚a przy pomocy kluczy rsa.

![Screen](screens/Screen3.png)

NastÄ™pnie skonfigurowaÅ‚em udostÄ™pnianie katalogu cloud przy pomocy nfs.

Niestety przy prÃ³bie uruchomienia programu na 2 maszynach wystÄ…piÅ‚ bÅ‚Ä…d, ktÃ³rego nie byÅ‚em w stanie rozwiÄ…zaÄ‡.

![Screen](screens/Screen1.png)

Niestety nie udaÅ‚o mi siÄ™ wykonaÄ‡ tego zadania, zyskaÅ‚em jednak wiedzÄ™, jak przebiega proces wykonywania programu na wielu maszynach w standardzie MPI.

## Nowe zadania

Ponowna implementacja algorytmu caÅ‚kujÄ…cego z wykorzystaniem rÃ³Å¼nych metod komunikacji.  
Sekcja dodana po sprecyzowaniu wymagaÅ„ 07.04.2020.

### CaÅ‚kowanie z wykorzystaniem komunikacji grupowej

Oryginalny program zostaÅ‚ zmodyfikowany tak, by korzystaÅ‚ z funkcji `MPI_Scatter()` oraz `MPI_Reduce()`.
Bardzo dobrze pasujÄ… one do realizowanego problemu, co pozwoliÅ‚o znacznie skrÃ³ciÄ‡ i uproÅ›ciÄ‡ oryginalny kod.

Program znajduje siÄ™ w katalogu [more_integration/group_communication](./more_integration/group_communication). Zmianom ulegÅ‚a funkcja `integrate()`, ktÃ³rej implementacja zaczyna siÄ™ w **linii 115**.

Uruchomienie programu jest takie same jak programu gÅ‚Ã³wnego i jest opisane w sekcji [Uruchomienie programu](#Uruchomienie-programu), z tym wyjÄ…tkiem, Å¼e z uwagi na zastosowanie `MPI_Scatter()` liczba punktÃ³w caÅ‚kowania musi byÄ‡Â podzielna przez liczbÄ™ procesÃ³w.

### CaÅ‚kowanie z wykorzystaniem komunikacji nieblokujÄ…cej

Oryginalny program zostaÅ‚ zmodyfikowany tak, by korzystaÅ‚ z funkcji `MPI_Isend()` oraz `MPI_Irecv()` zamiast ich blokujÄ…cych odpowiednikÃ³w.
UwaÅ¼am, Å¼e zadany problem nie wymaga komunikacji nieblokujÄ…cej i jej zastosowanie byÅ‚o zbÄ™dne.
Mimo tego sprÃ³bowaÅ‚em wykorzystaÄ‡ zalety pÅ‚ynÄ…ce z tej formy komunikacji.

Program znajduje siÄ™ w katalogu [more_integration/non_blocking_communication](./more_integration/non_blocking_communication). Zmianom ulegÅ‚a funkcja `integrate()`, ktÃ³rej implementacja zaczyna siÄ™ w **linii 105**.

Zastosowanie komunikacji nieblokujÄ…cej umoÅ¼liwiÅ‚o to, Å¼e gÅ‚Ã³wny proces nie musi czekaÄ‡ z rozpoczÄ™ciem obliczeÅ„ na odebranie danych przez inne procesy.

Bardzo ciekawie wyszÅ‚o teÅ¼ odbieranie wynikÃ³w czÄ…stkowych od procesÃ³w.  
DziÄ™ki zastosowaniu funkcji `MPI_Waitany()` proces gÅ‚Ã³wny moÅ¼e od razu dodaÄ‡ do sumy caÅ‚kowitej wynik czÄ…stkowy procesu, ktÃ³ry akurat skoÅ„czyÅ‚ pracÄ™. Pozwala to na zmniejszenie opÃ³Åºnienia wynikajÄ…cego z czekania zawsze na proces o najmniejszej randze.

Dla procesÃ³w wykonujÄ…cych jedynie obliczenia lepiej sprawdza siÄ™ komunikacja blokujÄ…ca, poniewaÅ¼ nie maja one innych zadaÅ„, ktÃ³re mogÅ‚yby realizowaÄ‡ w czasie oczekiwania na komunikacjÄ™.

Uruchomienie programu jest takie same jak programu gÅ‚Ã³wnego i jest opisane w sekcji [Uruchomienie programu](#Uruchomienie-programu).
